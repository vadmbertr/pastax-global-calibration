{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "954c7d85",
   "metadata": {},
   "source": [
    "This notebook interpolates variables from gridded satellite datasets to drifters space/time locations.\n",
    "\n",
    "Satellite and drifters data for the period 2010â€“2020 are:\n",
    "\n",
    "- Geostrophic currents from DUACS (https://doi.org/10.48670/moi-00148),\n",
    "- Stokes drift from WAVERYS/MFWAM (https://doi.org/10.48670/moi-00022),\n",
    "- Wind stress and 10 m velocity from ERA5 (https://doi.org/10.48670/moi-00185),\n",
    "- Drogued-SVP drifters from the GPD (https://doi.org/10.25921/x46c-3620)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aec7ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import dask\n",
    "dask.config.set({\"array.slicing.split_large_chunks\": True})\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af35d01",
   "metadata": {},
   "source": [
    "# Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e728484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for finding the data files\n",
    "start_datetime_str = \"1994-06-01\"\n",
    "end_datetime_str = \"2025-08-01\"\n",
    "output_directory = \"/summer/meom/workdir/bertrava/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e82d457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actually used start and end datetimes\n",
    "start_datetime = None\n",
    "end_datetime = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2c10e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_ds = xr.open_zarr(f\"gdp-v2.01.1_{start_datetime_str}_{end_datetime_str}.zarr\")\n",
    "if start_datetime is not None and end_datetime is not None:\n",
    "    gdp_ds = gdp_ds.where(\n",
    "        ((gdp_ds.time >= start_datetime) & (gdp_ds.time < end_datetime)).compute(), drop=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ba7bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_datetime = gdp_ds.time.min().values\n",
    "end_datetime = gdp_ds.time.max().values + np.timedelta64(1, \"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3310f217",
   "metadata": {},
   "outputs": [],
   "source": [
    "duacs_ds = xr.open_zarr(\n",
    "    f\"cmems_obs-sl_glo_phy-ssh_my_allsat-l4-duacs-0.125deg_P1D_{start_datetime_str}_{end_datetime_str}.zarr\"\n",
    ").sel(time=slice(start_datetime, end_datetime))\n",
    "\n",
    "waverys_ds = xr.open_zarr(\n",
    "    f\"cmems_mod_glo_wav_my_0.2deg_PT3H-i_{start_datetime_str}_{end_datetime_str}.zarr\"\n",
    ").sel(time=slice(start_datetime, end_datetime))\n",
    "\n",
    "if end_datetime > np.datetime64(\"2008-01-01\"):\n",
    "    if start_datetime > np.datetime64(\"2008-01-01\"):\n",
    "        era5_ds = xr.open_zarr(\n",
    "            f\"cmems_obs-wind_glo_phy_my_l4_0.125deg_PT1H_{start_datetime_str}_{end_datetime_str}.zarr\"\n",
    "        ).sel(time=slice(start_datetime, end_datetime))\n",
    "\n",
    "        era5_dss = [era5_ds,]\n",
    "    else:\n",
    "        era5_ds1 = xr.open_zarr(\n",
    "            f\"cmems_obs-wind_glo_phy_my_l4_0.125deg_PT1H_2008-01-01_{end_datetime_str}.zarr\"\n",
    "        ).sel(time=slice(start_datetime, end_datetime))\n",
    "\n",
    "        era5_ds2 = xr.open_zarr(\n",
    "            f\"cmems_obs-wind_glo_phy_my_l4_0.25deg_PT1H_{start_datetime_str}_2008-01-01.zarr\"\n",
    "        ).sel(time=slice(start_datetime, end_datetime))\n",
    "\n",
    "        era5_dss = [era5_ds1, era5_ds2,]\n",
    "else:\n",
    "    era5_ds = xr.open_zarr(\n",
    "        f\"cmems_obs-wind_glo_phy_my_l4_0.25deg_PT1H_{start_datetime_str}_{end_datetime_str}.zarr\"\n",
    "    ).sel(time=slice(start_datetime, end_datetime))\n",
    "    \n",
    "    era5_dss = [era5_ds,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c68f12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ease sequencial interpolation by sorting time dimension\n",
    "\n",
    "gdp_ds = gdp_ds.isel(points=np.argsort(gdp_ds.time.values))\n",
    "\n",
    "N = int(gdp_ds.points.size)\n",
    "gdp_ds[\"points\"] = np.arange(N, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc89229",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_store = \"gdp_interp_tmp.zarr\"\n",
    "chunk_size = 500_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d833ec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_ds = gdp_ds.chunk({\"points\": chunk_size}).drop_encoding()\n",
    "# gdp_ds.to_zarr(out_store, consolidated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398ea046",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_write = [\n",
    "    \"ugos\",\n",
    "    \"vgos\",\n",
    "    \"VSDX\",\n",
    "    \"VSDY\",\n",
    "    \"eastward_stress\",\n",
    "    \"northward_stress\",\n",
    "    \"eastward_wind\",\n",
    "    \"northward_wind\",\n",
    "]\n",
    "vars_to_ds = {\n",
    "    \"ugos\": duacs_ds,\n",
    "    \"vgos\": duacs_ds,\n",
    "    \"VSDX\": waverys_ds,\n",
    "    \"VSDY\": waverys_ds,\n",
    "    \"eastward_stress\": era5_dss[0],\n",
    "    \"northward_stress\": era5_dss[0],\n",
    "    \"eastward_wind\": era5_dss[0],\n",
    "    \"northward_wind\": era5_dss[0],\n",
    "}\n",
    "\n",
    "template = xr.Dataset(\n",
    "    {\n",
    "        v: (\n",
    "            (\"points\",), \n",
    "            np.full(N, np.nan, dtype=np.float32), \n",
    "            vars_to_ds[v][v].attrs,\n",
    "        )\n",
    "        for v in vars_to_write\n",
    "    },\n",
    "    coords={\"points\": gdp_ds.points},\n",
    ").chunk({\"points\": chunk_size})\n",
    "\n",
    "# template.to_zarr(out_store, mode=\"a\", consolidated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5128aea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "buf_lat = 0.25\n",
    "buf_lon = 0.25\n",
    "\n",
    "batch_size = 50_000  # should fit in memory and aligned with `chunk_size`\n",
    "start_i = 68350000  # for resuming interrupted runs\n",
    "for i in tqdm(range(start_i, N, batch_size)):\n",
    "    batch = gdp_ds.isel(points=slice(i, i + batch_size))\n",
    "\n",
    "    batch_time = batch.time\n",
    "    batch_lat = batch.lat\n",
    "    batch_lon = batch.lon\n",
    "\n",
    "    # matters for the last batch\n",
    "    bsz = batch_time.shape[0]\n",
    "    region = {\"points\": slice(i, i + bsz)}\n",
    "\n",
    "    print(\"Processing batch:\", i, \"to\", i + bsz, \"with\", batch_time.shape[0], \"points\")\n",
    "\n",
    "    time_min = batch_time.min().values\n",
    "    time_max = batch_time.max().values\n",
    "    lat_min = float(np.nanmin(batch_lat)) - buf_lat\n",
    "    lat_max = float(np.nanmax(batch_lat)) + buf_lat\n",
    "    lon_min = float(np.nanmin(batch_lon)) - buf_lon\n",
    "    lon_max = float(np.nanmax(batch_lon)) + buf_lon\n",
    "\n",
    "    # ------------------ DUACS (daily) ------------------\n",
    "    print(\"DUACS interpolation...\")\n",
    "    ds = duacs_ds.sel(time=slice(time_min - np.timedelta64(1, \"D\"), time_max + np.timedelta64(1, \"D\")))\n",
    "    ds = ds.sel(longitude=slice(lon_min, lon_max))\n",
    "    ds = ds.sel(latitude=slice(lat_min, lat_max))\n",
    "\n",
    "    not_done = True\n",
    "    while not_done:\n",
    "        try:\n",
    "            duacs_obs = ds[[\"ugos\", \"vgos\"]].interp(time=batch_time, latitude=batch_lat, longitude=batch_lon).compute()\n",
    "        except OSError:\n",
    "            print(\"OSError during DUACS interpolation\")\n",
    "            time.sleep(1)\n",
    "        else:\n",
    "            not_done = False\n",
    "    \n",
    "    duacs_obs= duacs_obs.drop_vars([\"time\", \"latitude\", \"longitude\"])\n",
    "    not_done = True\n",
    "    while not_done:\n",
    "        try:\n",
    "            duacs_obs.to_zarr(out_store, region=region, consolidated=False)\n",
    "        except OSError as e:\n",
    "            print(\"OSError while writing DUACS to_zarr\")\n",
    "            time.sleep(1)\n",
    "        else:\n",
    "            not_done = False\n",
    "\n",
    "    del ds, duacs_obs\n",
    "\n",
    "    # ------------------ WAVERYS (3-hourly) ------------------\n",
    "    print(\"WAVERYS interpolation...\")\n",
    "    ds = waverys_ds.sel(time=slice(time_min - np.timedelta64(3, \"h\"), time_max + np.timedelta64(3, \"h\")))\n",
    "    ds = ds.sel(longitude=slice(lon_min, lon_max))\n",
    "    ds = ds.sel(latitude=slice(lat_min, lat_max))\n",
    "\n",
    "    # remove duplicate times\n",
    "    ds = ds.isel(time=~ds.time.to_index().duplicated())\n",
    "\n",
    "    not_done = True\n",
    "    while not_done:\n",
    "        try:\n",
    "            waverys_obs = ds[[\"VSDX\", \"VSDY\"]].interp(\n",
    "                time=batch_time, latitude=batch_lat, longitude=batch_lon\n",
    "            ).compute()\n",
    "        except OSError:\n",
    "            print(\"OSError during WAVERYS interpolation\")\n",
    "            time.sleep(1)\n",
    "        else:\n",
    "            not_done = False\n",
    "\n",
    "    waverys_obs= waverys_obs.drop_vars([\"time\", \"latitude\", \"longitude\"])\n",
    "    not_done = True\n",
    "    while not_done:\n",
    "        try:\n",
    "            waverys_obs.to_zarr(out_store, region=region, consolidated=False)\n",
    "        except OSError as e:\n",
    "            print(\"OSError while writing WAVERYS to_zarr\")\n",
    "            time.sleep(1)\n",
    "        else:\n",
    "            not_done = False\n",
    "\n",
    "    del ds, waverys_obs\n",
    "\n",
    "    # ------------------ ERA5 (hourly) ------------------\n",
    "    print(\"ERA5 interpolation...\")\n",
    "\n",
    "    is_after_2008 = batch_time.values >= np.datetime64(\"2008-01-01\")\n",
    "    is_before_2008 = ~is_after_2008\n",
    "    \n",
    "    if is_before_2008.all():\n",
    "        continue\n",
    "\n",
    "    if is_after_2008.all():\n",
    "        pairs = [(is_after_2008, era5_dss[0])]\n",
    "    elif is_before_2008.all():\n",
    "        pairs = [(is_before_2008, era5_dss[1])]\n",
    "        pairs = []\n",
    "    else:\n",
    "        pairs = [(is_before_2008, era5_dss[1]), (is_after_2008, era5_dss[0])]\n",
    "\n",
    "    era5_obs_all = []\n",
    "    for mask, era5_ds in pairs:\n",
    "        ds = era5_ds.sel(time=slice(time_min - np.timedelta64(1, \"h\"), time_max + np.timedelta64(1, \"h\")))\n",
    "        ds = ds.sel(longitude=slice(lon_min, lon_max))\n",
    "        ds = ds.sel(latitude=slice(lat_min, lat_max))\n",
    "\n",
    "        not_done = True\n",
    "        while not_done:\n",
    "            try:\n",
    "                era5_obs = ds.interp(\n",
    "                    time=batch_time[mask], latitude=batch_lat[mask], longitude=batch_lon[mask]\n",
    "                ).compute()\n",
    "            except OSError:\n",
    "                print(\"OSError during ERA5 interpolation\")\n",
    "                time.sleep(1)\n",
    "            else:\n",
    "                not_done = False\n",
    "        \n",
    "        era5_obs_all.append(era5_obs)\n",
    "    \n",
    "    if len(era5_obs_all) == 0:\n",
    "        continue\n",
    "    \n",
    "    era5_obs_all = xr.concat(era5_obs_all, dim=\"points\").sortby(\"points\")\n",
    "    era5_obs_all = era5_obs_all.drop_vars([\"time\", \"latitude\", \"longitude\"])\n",
    "    \n",
    "    not_done = True\n",
    "    while not_done:\n",
    "        try:\n",
    "            era5_obs_all.to_zarr(out_store, region=region, consolidated=False)\n",
    "        except OSError as e:\n",
    "            print(\"OSError while writing ERA5 to_zarr\")\n",
    "            time.sleep(1)\n",
    "        else:\n",
    "            not_done = False\n",
    "\n",
    "    del ds, era5_obs_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cac2c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_ds_interp = xr.open_zarr(out_store)\n",
    "gdp_ds_interp.dropna(\n",
    "    dim=\"points\", how=\"any\"\n",
    ").chunk(\n",
    "    {\"points\": chunk_size}\n",
    ").to_zarr(f\"gdp_interp_{start_datetime_str}_{end_datetime_str}.zarr\", mode=\"w\", consolidated=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "456dd6f4",
   "metadata": {},
   "source": [
    "This notebook allows to download datasets and save them locally as Zarr stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03fb8590",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bertrava/.conda/envs/pastax_global_calibration/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import clouddrift as cd\n",
    "import copernicusmarine as cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e72b7ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_datetime_str = \"1994-06-01\"\n",
    "end_datetime_str = \"2025-08-01\"\n",
    "output_directory = \"/summer/meom/workdir/bertrava/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74e5f98",
   "metadata": {},
   "source": [
    "**GDP1h** (https://doi.org/10.1002/2016JC011716)\n",
    "\n",
    "- Position: latitude, longitude, time,\n",
    "- Velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b39c2b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bertrava/.conda/envs/pastax_global_calibration/lib/python3.11/site-packages/zarr/api/asynchronous.py:247: ZarrUserWarning: Consolidated metadata is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset_id = \"gdp-v2.01.1\"\n",
    "output_filename = f\"{dataset_id}_{start_datetime_str}_{end_datetime_str}.zarr\"\n",
    "\n",
    "if not os.path.exists(os.path.join(output_directory, output_filename)):\n",
    "    url_path = f\"https://noaa-oar-hourly-gdp-pds.s3.amazonaws.com/latest/{dataset_id}.zarr/\"\n",
    "    ds = xr.open_zarr(url_path)\n",
    "    \n",
    "    ds = ds[\n",
    "        [\"rowsize\", \"typebuoy\", \"drogue_status\", \"err_ve\", \"err_vn\", \"time\", \"lat\", \"lon\", \"ve\", \"vn\"]\n",
    "    ]\n",
    "\n",
    "    ds.typebuoy.load()\n",
    "    ds = cd.ragged.subset(\n",
    "        ds, {\"typebuoy\": lambda tb: np.char.find(tb.astype(str), \"SVP\") != -1}, row_dim_name=\"traj\"\n",
    "    )\n",
    "\n",
    "    ds = ds.drop_vars(\"typebuoy\")\n",
    "\n",
    "    ds.drogue_status.load()\n",
    "    ds = cd.ragged.subset(\n",
    "        ds, {\"drogue_status\": lambda ds: ds == True}, row_dim_name=\"traj\"\n",
    "    )\n",
    "\n",
    "    ds = ds.drop_vars(\"drogue_status\")\n",
    "\n",
    "    ds.time.load()\n",
    "    ds = cd.ragged.subset(\n",
    "        ds,\n",
    "        {\"time\": lambda t: (t >= np.datetime64(start_datetime_str)) & (t < np.datetime64(end_datetime_str))},\n",
    "        row_dim_name=\"traj\"\n",
    "    )\n",
    "\n",
    "    ds.ve.load()\n",
    "    ds.vn.load()\n",
    "    ds.err_ve.load()\n",
    "    ds.err_vn.load()\n",
    "    ds.lat.load()\n",
    "    ds.lon.load()\n",
    "\n",
    "    def remove_nan(ve, vn, err_ve, err_vn, time, lat, lon):\n",
    "        mask = (\n",
    "            np.isfinite(ve) & np.isfinite(vn) & \n",
    "            np.isfinite(err_ve) & np.isfinite(err_vn) & \n",
    "            ~np.isnat(time) & \n",
    "            np.isfinite(lat) & np.isfinite(lon)\n",
    "        )\n",
    "        return mask\n",
    "\n",
    "    ds = cd.ragged.subset(\n",
    "        ds, {(\"ve\", \"vn\", \"err_ve\", \"err_vn\", \"time\", \"lat\", \"lon\"): remove_nan}, row_dim_name=\"traj\"\n",
    "    )\n",
    "\n",
    "    ds = ds.drop_vars([\"err_ve\", \"err_vn\"])\n",
    "\n",
    "    ds = cd.ragged.subset(\n",
    "        ds, {(\"ve\", \"vn\"): lambda ve, vn: (np.abs(ve) <= 3) & (np.abs(vn) <= 3)}, row_dim_name=\"traj\"\n",
    "    )\n",
    "\n",
    "    ds = xr.Dataset(\n",
    "        data_vars={\n",
    "            \"id\": (\"points\", np.repeat(ds.id.values, ds.rowsize.values), {\"long_name\": \"Drifter ID\"}),\n",
    "            \"time\": (\"points\", ds.time.values, ds.time.attrs),\n",
    "            \"lat\": (\"points\", ds.lat.values.astype(np.float32), ds.lat.attrs),\n",
    "            \"lon\": (\"points\", ds.lon.values.astype(np.float32), ds.lon.attrs),\n",
    "            \"ve\": (\"points\", ds.ve.values.astype(np.float32), ds.ve.attrs),\n",
    "            \"vn\": (\"points\", ds.vn.values.astype(np.float32), ds.vn.attrs)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    ds.to_zarr(os.path.join(output_directory, output_filename), compute=True, consolidated=True)\n",
    "else:\n",
    "    ds = xr.open_zarr(os.path.join(output_directory, output_filename))\n",
    "\n",
    "start_datetime = (ds.time.values.min() - np.timedelta64(1, \"D\"))\n",
    "end_datetime = (ds.time.values.max() + np.timedelta64(1, \"D\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed92c2cc",
   "metadata": {},
   "source": [
    "**DUACS** (https://doi.org/10.48670/moi-00148)\n",
    "\n",
    "- SSH\n",
    "- geostrophy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333b4ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"cmems_obs-sl_glo_phy-ssh_my_allsat-l4-duacs-0.125deg_P1D\"\n",
    "output_filename = f\"{dataset_id}_{start_datetime_str}_{end_datetime_str}.zarr\"\n",
    "\n",
    "if not os.path.exists(os.path.join(output_directory, output_filename)):\n",
    "    cm.subset(\n",
    "        dataset_id, \n",
    "        variables=[\"sla\", \"adt\", \"ugos\", \"vgos\"],\n",
    "        start_datetime=str(start_datetime),\n",
    "        end_datetime=str(end_datetime),\n",
    "        output_filename=output_filename,\n",
    "        output_directory=output_directory\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5670e2",
   "metadata": {},
   "source": [
    "**ERA5** (https://doi.org/10.48670/moi-00185)\n",
    "\n",
    "- wind stress\n",
    "- wind velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66e745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if end_datetime > np.datetime64(\"2008-01-01\"):\n",
    "    if start_datetime > np.datetime64(\"2008-01-01\"):\n",
    "        start_datetimes = [start_datetime,]\n",
    "        end_datetimes = [end_datetime,]\n",
    "        start_datetimes_str = [start_datetime_str,]\n",
    "        end_datetimes_str = [end_datetime_str,]\n",
    "        dataset_ids = [\"cmems_obs-wind_glo_phy_my_l4_0.125deg_PT1H\",]\n",
    "    else:\n",
    "        start_datetimes = [start_datetime, np.datetime64(\"2008-01-01\")]\n",
    "        end_datetimes = [np.datetime64(\"2008-01-01\"), end_datetime]\n",
    "        start_datetimes_str = [start_datetime_str, \"2008-01-01\"]\n",
    "        end_datetimes_str = [\"2008-01-01\", end_datetime_str]\n",
    "        dataset_ids = [\"cmems_obs-wind_glo_phy_my_l4_0.25deg_PT1H\", \"cmems_obs-wind_glo_phy_my_l4_0.125deg_PT1H\"]\n",
    "else:\n",
    "    start_datetimes = [start_datetime,]\n",
    "    end_datetimes = [end_datetime,]\n",
    "    start_datetimes_str = [start_datetime_str,]\n",
    "    end_datetimes_str = [end_datetime_str,]\n",
    "    dataset_ids = [\"cmems_obs-wind_glo_phy_my_l4_0.25deg_PT1H\",]\n",
    "\n",
    "for dataset_id, _start_datetime, _end_datetime, _start_datetime_str, _end_datetime_str in zip(\n",
    "    dataset_ids, start_datetimes, end_datetimes, start_datetimes_str, end_datetimes_str\n",
    "):\n",
    "\n",
    "    output_filename = f\"{dataset_id}_{_start_datetime_str}_{_end_datetime_str}.zarr\"\n",
    "    \n",
    "    if not os.path.exists(os.path.join(output_directory, output_filename)):\n",
    "        cm.subset(\n",
    "            dataset_id, \n",
    "            variables=[\"eastward_wind\", \"northward_wind\", \"eastward_stress\", \"northward_stress\"],\n",
    "            start_datetime=str(_start_datetime),\n",
    "            end_datetime=str(_end_datetime),\n",
    "            output_filename=output_filename,\n",
    "            output_directory=output_directory\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fe8d14",
   "metadata": {},
   "source": [
    "**WAVERYS/MFWAM** (https://doi.org/10.48670/moi-00022)\n",
    "\n",
    "- Stokes drift at the surface\n",
    "- Waves (wind, primary swell, secondary swell) parameters (significant wave height, period, direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc6b942",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"cmems_mod_glo_wav_my_0.2deg_PT3H-i\"\n",
    "output_filename = f\"{dataset_id}_{start_datetime_str}_{end_datetime_str}.zarr\"\n",
    "\n",
    "time_batches = pd.date_range(start=start_datetime, end=end_datetime, freq=\"1ME\")\n",
    "\n",
    "store = os.path.join(output_directory, output_filename)\n",
    "\n",
    "for i in tqdm(range(len(time_batches) - 1)):\n",
    "    t0 = time_batches[i]\n",
    "    t1 = time_batches[i + 1]\n",
    "\n",
    "    ds_batch = cm.open_dataset(\n",
    "        dataset_id,\n",
    "        variables=[\"VSDX\", \"VSDY\"],\n",
    "        start_datetime=str(t0),\n",
    "        end_datetime=str(t1),\n",
    "    )\n",
    "\n",
    "    ds_batch = ds_batch.drop_encoding().chunk({\"time\": 72, \"latitude\": 90, \"longitude\": 180})\n",
    "\n",
    "    mode = \"w\" if i == 0 else \"a\"\n",
    "    append_dim = None if i == 0 else \"time\"\n",
    "\n",
    "    ds_batch.to_zarr(store, mode=mode, append_dim=append_dim, align_chunks=True, consolidated=False)\n",
    "\n",
    "    del ds_batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
